---
output: 
  html_document:
    keep_md: true
    html_widgets: true
---

[Project Home](../README.md)

# A collapsible section with markdown
<details>
  <summary>Click to expand!</summary>
  
  ## Heading
  1. A numbered
  2. list
     * With some
     * Sub bullets
</details>

Three datasets in .CSV format were downloaded from the Alzheimer's Disease Neuroimaging Initiative Study Data repository. ADNI data is freely accessible to all registered users.

## Tau-PET

Longitudinal 18F-AV-1451 tau-PET data was acquired from Study Data/Imaging/PET Image Analysis/UC Berkeley - AV1451 Analysis [ADNI2,3] (version: 5/12/2020). This CSV file contains 1,121 rows and 241 columns. Each row represents one tau-PET scan; some subjects had repeated scans separated by approximately one year, while other subjects had only one scan.

Columns include subject information including anonymized subject ID, visit code, and PET exam date. The other columns encode regional volume and tau-PET uptake. Specifically, there are 123 distinct cortical and subcortical regions of interest (ROIs), each of which has a volume field (in mm^3) and a tau-PET uptake field, called the Standardized Uptake Value Ratio (SUVR). The SUVR value is normalized to the tau-PET uptake in the inferior cerebellum gray matter, a commonly-used region for tau normalization given the lack of inferior cerebellar tau pathology in Alzheimer's Disease. These 123 ROIs were delineated by first co-registering the tau-PET image to a high-resolution structural T1-weighted MPRAGE acquired in the same imaging session, and then applying FreeSurfer (v5.3) for automated regional segmentation and parcellation. Furthermore, to mitigate issues with lower voxel resolution in PET imaging, partial volume correction was applied to use probabilistic tissue segmentation maps to refine individual ROIs.

Note: these PET processing steps were all performed by Susan Landau, Deniz Korman, and William Jagust at the Helen Wills Neuroscience Institute, UC Berkeley and Lawrence Berkeley National Laboratory.


## Alzheimer's Disease Assessment Scale-13

Longitudinal Alzheimer's Disease Assessment Scale-13 (ADAS13) cognitive score dataset was downloaded from Study Data/Assessments/Neuropsychological/Alzheimer's Disease Assessment Scale (ADAS) [ADNIGO,2,3]. This CSV file contains 6,695 rows and 121 columns. Each row represents one clinical visit; most subjects had several clinical visits separated by approximately one year each, though some subjects had only one clinical visit.

The ADAS13 score ranges from 0 to 70 and represents a composite score based on thirteen individual assessment components. A score of 0 reflects no cognitive impairment, while a score of 70 indicates severe cognitive impairment. There are multiple columns per individual ADAS component, indicating information such as cognitive task assessed, time to complete the task, and task completion score. There are also columns pertaining to subject/visit information, such as anonymized subject ID, visit code, site ID, ADNI project phase, and exam date.

## General Cognitive Status

The general cognitive status and cognitive diagnosis dataset was downloaded from Study Data/Assessments/Diagnosis/Diagnostic Summary [ADNI1,GO,2,3]. This CSV file contains 12,268 rows and 54 columns. Certain columns only pertain to certain subsets of the data depending on the project cohort (ADNI1, ADNI-GO, ADNI2, or ADNI3). There are columns for subject/visit information such as anonymized subject ID, ADNI project phase, and exam date, and the rest of the columns indicate cognitive diagnosis information such as probability of dementia due to AD, current cognitive diagnosis, and change in cognitive status from the previous visit. These metrics were all evaluated by neurologists.


### Packages used:
```{r}
library(tidyverse)
library(knitr)
library(kableExtra)
library(plotly)
library(lubridate)
library(forcats)
```

### Load tau-PET data, as downloaded from ADNI:
```{r}
og_tau <- read.csv("../../ADNI_Data/Raw_Data/UCBERKELEYAV1451_PVC_05_12_20.csv")
str(og_tau)
```


### Examine scan date distribution:

```{r}
og_tau %>%
  select(RID, EXAMDATE) %>%
  mutate(Scan_Date = as.Date(EXAMDATE, format="%m/%d/%Y")) %>%
  plot_ly(x=~Scan_Date, type="histogram") %>%
  layout(title = 'Tau-PET Scan Date Distribution',
         xaxis = list(title = 'Scan Date',
                      zeroline = TRUE),
         yaxis = list(title = 'Number of PET Scans')) 
```

### Examine number of longitudinal PET scans per subject (i.e. average number of PET scans each subject had):

```{r}
p_num_long <- og_tau %>%
  mutate(RID=as.character(RID)) %>%
  group_by(RID) %>%
  summarise(n_scans=n()) %>%
  ggplot(., aes(x=fct_reorder(RID, n_scans, .desc=T), y=n_scans)) +
  geom_bar(stat="identity", aes(fill=n_scans, color=n_scans)) +
  labs(fill="Count", color="Count") +
  ggtitle("Number of Longitudinal PET Scans per Subject") +
  ylab("Number of PET Scans") +
  xlab("Subject") +
  theme(axis.text.x=element_blank(),
        plot.title=element_text(hjust=0.5)) 

ggplotly(p_num_long)
```

### How many subjects have at least two longitudinal scans?

I am going to focus exclusively on subjects with at least two scans, to examine changes in tau accumulation over time. 
```{r}
og_tau %>%
  mutate(RID=as.character(RID)) %>%
  group_by(RID) %>%
  summarise(n_scans=n()) %>%
  filter(n_scans>=2) %>%
  ungroup() %>%
  summarise(`Number of Subjects`=n(),
            `Number of Scans in Total`=sum(n_scans)) %>%
  kable(., booktabs=T)
```

### What is the typical time interval between consecutive tau-PET scans?

The ADNI tau-PET scans are intended to be spaced approximately one year apart for each subject, but the temporal distribution should still be examined:

```{r}
p_pet_interval <- og_tau %>%
  select(RID, EXAMDATE) %>%
  mutate(Scan_Date = as.Date(EXAMDATE, format="%m/%d/%Y")) %>%
  group_by(RID) %>%
  mutate(n_scans=n()) %>%
  filter(n_scans>=2) %>%
  mutate(Years_between_Scans = 
           as.numeric((Scan_Date - lag(Scan_Date, 
                                       default = Scan_Date[1]))/365)) %>%
  filter(Years_between_Scans>0) %>%
  ggplot(., aes(x=Years_between_Scans)) +
  geom_histogram(stat="count", color="dodgerblue3") +
  ggtitle("Years in between Tau-PET Scans per Subject") +
  ylab("Frequency") +
  xlab("# Years between two consecutive scans for a subject") +
  theme_minimal() +
  theme(plot.title=element_text(hjust=0.5)) 

ggplotly(p_pet_interval)
```

### Is there any missing tau-PET SUVR uptake data for the measured ROIs?

```{r}
og_tau %>%
  select(-VISCODE, -VISCODE2, -update_stamp) %>%
  group_by(RID) %>%
  mutate(n_scans=n()) %>%
  filter(n_scans>=2) %>%
  select(-n_scans) %>%
  ungroup() %>%
  select(!matches("VOLUME")) %>%
  pivot_longer(cols=c(-RID, -EXAMDATE), names_to="ROI", values_to="SUVR") %>%
  group_by(ROI) %>%
  summarise(`Percent Missing` = sum(is.na(SUVR))/n(),
            `Number Missing` = sum(is.na(SUVR))) %>%
  kable(., booktabs=T)
```

### What is the average tau-PET SUVR uptake by ROI?

```{r}
p_roi_suvr <- og_tau %>%
  select(-VISCODE, -VISCODE2, -update_stamp) %>%
  group_by(RID) %>%
  mutate(n_scans=n()) %>%
  filter(n_scans>=2) %>%
  select(-n_scans) %>%
  select(!matches("VOLUME")) %>%
  pivot_longer(cols=c(-RID, -EXAMDATE), names_to="ROI", values_to="SUVR") %>%
  mutate(ROI = str_replace(ROI, "_SUVR", "")) %>%
  group_by(ROI) %>%
  summarise(Mean_SUVR=mean(SUVR, na.rm=T),
            SD_SUVR = sd(SUVR, na.rm=T),
            ymin = Mean_SUVR-SD_SUVR,
            ymax = Mean_SUVR+SD_SUVR) %>%
  ggplot(data=., mapping=aes(x=fct_reorder(ROI, Mean_SUVR, .desc=F), 
                             y=Mean_SUVR, fill=Mean_SUVR,
                             label = ROI)) +
  geom_bar(stat="identity", show.legend=F) +
  geom_errorbar(aes(ymin=ymin, ymax=ymax), width=0) +
  coord_flip() +
  theme_minimal() +
  ylab("Mean Tau-PET SUVR") +
  xlab("Region of Interest") +
  ggtitle("Mean Tau-PET SUVR by ROI")


ggplotly(p_roi_suvr, height=1000, width=600, tooltip=c("label", "y"))
```

### Load ADAS cognitive score data, as downloaded from ADNI:
```{r}
adas <- read.csv("../../ADNI_Data/Raw_Data/ADAS_ADNIGO23.csv")
str(adas)
```


The primary variable of interest is `TOTSCORE`, reflecting the sum of the ADAS component sub-scores.

```{r}
summary(adas$TOTSCORE)
```
As verified using `summary()`, this metric ranges from 0 (no cognitive impairment) to 70 (severe cognitive impairment). There are 61 missing data points for this feature, though there are far more records here than will actually be used for analysis. This dataset includes subjects without tau-PET images as well as exam sessions that did not coincide with tau-PET scan sessions, both of which will be excluded once the datasets are merged.


### Examine ADAS cognitive assessment date distribution:

```{r}
adas %>%
  select(RID, USERDATE) %>%
  mutate(Exam_Date = as.Date(USERDATE, format="%m/%d/%Y")) %>%
  plot_ly(x=~Exam_Date, type="histogram") %>%
  layout(title = 'ADAS-13 Cognitive Assessment Date Distribution',
         xaxis = list(title = 'Exam Date',
                      zeroline = TRUE),
         yaxis = list(title = 'Number of Assessed Subjects')) 
```


### Examine number of longitudinal ADAS-13 cognitive assessments per subject:

```{r}
p_adas_long <- adas %>%
  mutate(RID=as.character(RID)) %>%
  group_by(RID) %>%
  summarise(n_exams=n()) %>%
  ggplot(., aes(x=fct_reorder(RID, n_exams, .desc=T), y=n_exams, label=RID)) +
  geom_bar(stat="identity", aes(fill=n_exams, color=n_exams)) +
  labs(fill="Count", color="Count") +
  ggtitle("Number of Longitudinal ADAS-13 Assessments per Subject") +
  ylab("Number of ADAS-13 Scores") +
  xlab("Subject") +
  theme(axis.text.x=element_blank(),
        plot.title=element_text(hjust=0.5)) 

ggplotly(p_adas_long, tooltip = c("label", "y"))
```


### How many subjects have at least two ADAS-13 cognitive assessments?

I am going to focus exclusively on subjects with at least two longitudinal ADAS-13 assessments, to predict change over time based on regional tau accumulation. 
```{r}
adas %>%
  mutate(RID=as.character(RID)) %>%
  group_by(RID) %>%
  summarise(n_exams=n()) %>%
  filter(n_exams>=2) %>%
  ungroup() %>%
  summarise(`Number of Subjects`=n(),
            `Number of ADAS-13 Assessments in Total`=sum(n_exams)) %>%
  kable(., booktabs=T)
```

### What is the typical time interval between consecutive ADAS-13 assessments?

While ADNI subjects are typically assessed annually, the temporal distribution should still be examined:

```{r}
p_adas_interval <- adas %>%
  select(RID, USERDATE) %>%
  mutate(Exam_Date = as.Date(USERDATE, format="%m/%d/%Y")) %>%
  group_by(RID) %>%
  mutate(n_exams=n()) %>%
  filter(n_exams>=2) %>%
  arrange(Exam_Date) %>%
  mutate(Years_between_ADAS13 = 
           as.numeric((Exam_Date - lag(Exam_Date, 
                                       default = Exam_Date[1]))/365)) %>%
  filter(Years_between_ADAS13>0) %>%
  ggplot(., aes(x=Years_between_ADAS13)) +
  geom_histogram(stat="count", color="dodgerblue3") +
  ggtitle("Years in between ADAS-13 Assessments per Subject") +
  ylab("Frequency") +
  xlab("# Years between two consecutive ADAS-13 assessments") +
  theme_minimal() +
  theme(plot.title=element_text(hjust=0.5)) 

ggplotly(p_adas_interval)
```


### What is the ADAS-13 total score distribution?

```{r}
p_adas_scores <- adas %>%
  mutate(Exam_Date = as.Date(USERDATE, format="%m/%d/%Y")) %>%
  group_by(RID) %>%
  mutate(n_exams=n()) %>%
  filter(n_exams>=2) %>%
  ggplot(data=., mapping=aes(x=TOTSCORE)) +
  geom_histogram(aes(y=..count..)) +
  theme_minimal() +
  ylab("# of Occurences") +
  xlab("ADAS-13 Total Score") +
  ggtitle("Distribution of ADAS-13 Total Scores")

ggplotly(p_adas_scores)
```

### Load general cognition data, as downloaded from ADNI:
```{r}
cog.df <- read.csv("../../ADNI_Data/Raw_Data/DXSUM_PDXCONV_ADNIALL.csv")
str(cog.df)
```
A value of -4 indicates that the value is missing.

This dataset is a bit tricky, as certain columns only pertain to specific ADNI cohorts. For my purposes, I am interested in the following columns: 

* DXCURREN: current cognitive diagnosis (ADNI1)
    1=NL;2=MCI;3=AD
    
* DXCONV: has there been a change in cognitive status from previous visit? (ADNI1)
    1=Yes - Conversion;2=Yes - Reversion; 0=No
      Conversion = CN to MCI or MCI to dementia
      Reversion = dementia to MCI or MCI to CN


* DXCHANGE: change in cognitive status from previous visit (ADNI2. ADNI-GO)
    1=Stable: NL; 2=Stable: MCI; 3=Stable: Dementia; 4=Conversion: NL to MCI; 5=Conversion: MCI to Dementia; 6=Conversion: NL to Dementia; 7=Reversion: MCI to NL; 8=Reversion: Dementia to MCI; 9=Reversion: Dementia to NL


* DIAGNOSIS: current cognitive diagnosis at date of exam (ADNI3)
  1=Yes - Conversion;2=Yes - Reversion; 0=No

```{r}
summary(cog.df %>% select(DXCURREN, DXCONV, DXCHANGE, DIAGNOSIS))
```

The large numbers of NA values in each column are to be expected given the disjointed nature of the features. These distinct features will be integrated in Part Three, Data Preparation.


### Examine general cognitive assessment date distribution:

```{r}
cog.df %>%
  select(RID, EXAMDATE) %>%
  mutate(Exam_Date = as.Date(EXAMDATE, format="%m/%d/%Y")) %>%
  plot_ly(x=~Exam_Date, type="histogram") %>%
  layout(title = 'General Cognitive Assessment Date Distribution',
         xaxis = list(title = 'Exam Date',
                      zeroline = TRUE),
         yaxis = list(title = 'Number of Assessed Subjects')) 
```

It seems that one subject's exam date was incorrectly inputted as 2109: 

```{r}
cog.df %>%
  mutate(Exam_Date = as.Date(EXAMDATE, format="%m/%d/%Y")) %>%
  mutate(Year=year(Exam_Date)) %>%
  filter(Year==2109) %>%
  select(-PTID) %>%
  select(Phase:EXAMDATE) %>%
  kable(., booktabs=T)
```

Since the data was entered into the ADNI databse in 2019, a reasonable assumption would be that the exam date should read 7/26/2019 instead of 7/26/2109. This will be addressed in Data Preparation. For now, I'll filter that data point out to visualize the temporal distribution better:

```{r}
cog.df %>%
  select(RID, EXAMDATE) %>%
  mutate(Exam_Date = as.Date(EXAMDATE, format="%m/%d/%Y")) %>%
  filter(year(Exam_Date)!=2109) %>%
  plot_ly(x=~Exam_Date, type="histogram") %>%
  layout(title = 'General Cognitive Assessment Date Distribution',
         xaxis = list(title = 'Exam Date',
                      zeroline = TRUE),
         yaxis = list(title = 'Number of Assessed Subjects')) 
```


### Examine number of longitudinal general cognitive assessments per subject:

```{r}
p_cog_long <- cog.df %>%
  mutate(RID=as.character(RID)) %>%
  group_by(RID) %>%
  summarise(n_exams=n()) %>%
  ggplot(., aes(x=fct_reorder(RID, n_exams, .desc=T), y=n_exams, label=RID)) +
  geom_bar(stat="identity", aes(fill=n_exams, color=n_exams)) +
  labs(fill="Count", color="Count") +
  ggtitle("Number of Longitudinal General Cognitive Assessments per Subject") +
  ylab("Number of Cognitive Assessments") +
  xlab("Subject") +
  theme(axis.text.x=element_blank(),
        plot.title=element_text(hjust=0.5)) 

ggplotly(p_cog_long, tooltip = c("label", "y"))
```

### How many subjects have at least two general cognitive assessments?

I am going to focus exclusively on subjects with at least two longitudinal general cognitive assessments, to predict conversion to a more severely impaired cognitive status based on regional tau accumulation over time. 
```{r}
cog.df %>%
  mutate(RID=as.character(RID)) %>%
  group_by(RID) %>%
  summarise(n_exams=n()) %>%
  filter(n_exams>=2) %>%
  ungroup() %>%
  summarise(`Number of Subjects`=n(),
            `Number of General Cognitive Assessments in Total`=sum(n_exams)) %>%
  kable(., booktabs=T)
```

### What is the typical time interval between consecutive general cognitive assessments?

While ADNI subjects are typically assessed annually, the temporal distribution should still be examined. Note: I have filtered out the subject with the incorrectly-inputted exam date for visualization.

```{r}
p_cog_interval <- cog.df %>%
  select(RID, EXAMDATE) %>%
  mutate(Exam_Date = as.Date(EXAMDATE, format="%m/%d/%Y")) %>%
  filter(year(Exam_Date) != 2109) %>%
  group_by(RID) %>%
  mutate(n_exams=n()) %>%
  filter(n_exams>=2) %>%
  arrange(Exam_Date) %>%
  mutate(Years_between_Cog_Assess = 
           as.numeric((Exam_Date - lag(Exam_Date, 
                                       default = Exam_Date[1]))/365)) %>%
  filter(Years_between_Cog_Assess>0) %>%
  ggplot(., aes(x=Years_between_Cog_Assess)) +
  geom_histogram(stat="count", color="dodgerblue3") +
  ggtitle("Years in between General Cognitive Assessments per Subject") +
  ylab("Frequency") +
  xlab("# Years between two consecutive assessments") +
  theme_minimal() +
  theme(plot.title=element_text(hjust=0.5)) 

ggplotly(p_cog_interval)
```


### How is cognitive status distributed in the distinct ADNI cohorts?


```{r}
p_adni1_curr <- cog.df %>%
  filter(!is.na(DXCURREN)) %>%
  group_by(RID) %>%
  mutate(n_exams=n()) %>%
  filter(n_exams>=2) %>%
  mutate(DXCURREN = factor(DXCURREN, levels=c(1,2,3),
                           labels=c("Cognitively Normal",
                                    "Mild Cognitive Impairment", 
                                    "Dementia"))) %>%
  ggplot(data=., mapping=aes(x=DXCURREN, fill=DXCURREN)) +
  geom_histogram(stat="count", show.legend=F) +
  theme_minimal() +
  ylab("# of Occurences") +
  xlab("Current Diagnosis in ADNI1") +
  ggtitle("Distribution of Current Diagnosis in ADNI1") +
  theme(plot.title=element_text(hjust=0.5),
        legend.position='none')

ggplotly(p_adni1_curr)
```

```{r}
p_adni3_curr <- cog.df %>%
  filter(!is.na(DIAGNOSIS)) %>%
  group_by(RID) %>%
  mutate(n_exams=n()) %>%
  filter(n_exams>=2) %>%
  mutate(DIAGNOSIS = factor(DIAGNOSIS, levels=c(1,2,3),
                           labels=c("Cognitively Normal",
                                    "Mild Cognitive Impairment", 
                                    "Dementia"))) %>%
  ggplot(data=., mapping=aes(x=DIAGNOSIS, fill=DIAGNOSIS)) +
  geom_histogram(stat="count", show.legend=F) +
  theme_minimal() +
  ylab("# of Occurences") +
  xlab("Current Diagnosis in ADNI3") +
  ggtitle("Distribution of Current Diagnosis in ADNI3") +
  theme(plot.title=element_text(hjust=0.5),
        legend.position='none')

ggplotly(p_adni3_curr)
```


```{r}
p_adni1_change <- cog.df %>%
  filter(!is.na(DXCONV)) %>%
  group_by(RID) %>%
  mutate(n_exams=n()) %>%
  filter(n_exams>=2) %>%
  mutate(DXCONV = factor(DXCONV, levels=c(0,1,2),
                           labels=c("Stable",
                                    "Conversion", 
                                    "Reversion"))) %>%
  ggplot(data=., mapping=aes(x=DXCONV, fill=DXCONV)) +
  geom_histogram(stat="count", show.legend=F) +
  theme_minimal() +
  ylab("# of Occurences") +
  xlab("Cognitive Status Change in ADNI1") +
  ggtitle("Distribution of Cognitive Status Changes in ADNI1") +
  theme(plot.title=element_text(hjust=0.5),
        legend.position='none')

ggplotly(p_adni1_change)
```

```{r}
p_adni2_change <- cog.df %>%
  filter(!is.na(DXCHANGE)) %>%
  group_by(RID) %>%
  mutate(n_exams=n()) %>%
  filter(n_exams>=2) %>%
  mutate(DXCHANGE = factor(DXCHANGE, levels=c(1:9),
                           labels=c("Stable CN",
                                    "Stable MCI",
                                    "Stable Dementia",
                                    "CN to MCI",
                                    "MCI to Dementia",
                                    "CN to Dementia",
                                    "MCI to CN",
                                    "Dementia to MCI",
                                    "Dementia to CN"))) %>%
  ggplot(data=., mapping=aes(x=DXCHANGE, fill=DXCHANGE)) +
  geom_histogram(stat="count", show.legend=F) +
  theme_minimal() +
  ylab("# of Occurences") +
  xlab("Cognitive Status Change in ADNI2") +
  ggtitle("Distribution of Cognitive Status Changes in ADNI2") +
  theme(plot.title=element_text(hjust=0.5),
        legend.position='none',
        axis.text.x=element_text(angle=45))

ggplotly(p_adni2_change)
```
